{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# LangChain Overview \n",
        "\n",
        "[LangChain](https://python.langchain.com/docs/get_started/introduction) is a framework for developing applications powered by language models. \n",
        "\n",
        "The main value props of LangChain are:\n",
        "\n",
        "1. **Components**: abstractions for working with language models, along with a collection of implementations for each abstraction. \n",
        "2. **Off-the-shelf chains**: a structured assembly of components for accomplishing specific higher-level tasks\n",
        "\n",
        "Off-the-shelf chains make it easy to get started. For complex applications, components make it easy to customize existing chains and build new ones."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UByBGO3HWdmn",
        "outputId": "4db6a65f-f2b8-4e15-fff7-86a60d52449c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q install openai langchain huggingface_hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "YCNgslXFWqQs"
      },
      "outputs": [],
      "source": [
        "# load envirenmental variables from .env file \n",
        "from dotenv import load_dotenv, find_dotenv\n",
        "_ = load_dotenv(find_dotenv()) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "There are two types of language models, which in LangChain are called:\n",
        "\n",
        "* LLMs: this is a language model which takes a string as input and returns a string\n",
        "* ChatModels: this is a language model which takes a list of messages as input and returns a message\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 1.1. Build first LLM model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "muGwyE6_XNmE",
        "outputId": "27b58079-01c9-453b-bcdb-02adff3081cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "To get to the other side.\n"
          ]
        }
      ],
      "source": [
        "from langchain.llms import OpenAI\n",
        "\n",
        "# Similar au call API directly\n",
        "llm = OpenAI(model_name = 'text-davinci-003',\n",
        "             temperature=0.9,\n",
        "             max_tokens = 256\n",
        "             )\n",
        "\n",
        "text = \"Why did the chicken cross the road?\"\n",
        "output = llm(text)\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cR0UtxNCbtwG"
      },
      "source": [
        "# 1.2. Chat model\n",
        "\n",
        "A *chat model* takes a list of ChatMessages as an input and returns a ChatMessage.\n",
        "\n",
        "There are tree type of the messages :\n",
        "\n",
        "* `SystemChatMessage` : A chat message representing information that should be instructions to the AI system.\n",
        "\n",
        "* `HumanChatMessage` : A chat message representing information coming from a human interacting with the AI system.   \n",
        "\n",
        "* `AIChatMessage` : A chat message representing information coming from the AI system."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "P5P-2KI4bdFr"
      },
      "outputs": [],
      "source": [
        "from langchain.schema import (\n",
        "    AIMessage,\n",
        "    HumanMessage,\n",
        "    SystemMessage\n",
        ")\n",
        "\n",
        "from langchain.chat_models import ChatOpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "5qpDVqEMcGQp"
      },
      "outputs": [],
      "source": [
        "chat = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.3)\n",
        "messages = [\n",
        "    SystemMessage(content=\"You are an expert data scientist\"),\n",
        "    HumanMessage(content=\"Write a Python script thet trains a neural network on simulated data\")\n",
        "]\n",
        "response=chat(messages)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MOjkqqFed1xu",
        "outputId": "dc565a8c-963a-486f-dbdb-1bc7b422811a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sure! Here's an example of a Python script that trains a neural network on simulated data using the Keras library:\n",
            "\n",
            "```python\n",
            "import numpy as np\n",
            "from keras.models import Sequential\n",
            "from keras.layers import Dense\n",
            "\n",
            "# Generate simulated data\n",
            "np.random.seed(0)\n",
            "X = np.random.rand(100, 2)\n",
            "y = np.random.randint(2, size=100)\n",
            "\n",
            "# Define the neural network model\n",
            "model = Sequential()\n",
            "model.add(Dense(4, input_dim=2, activation='relu'))\n",
            "model.add(Dense(1, activation='sigmoid'))\n",
            "\n",
            "# Compile the model\n",
            "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
            "\n",
            "# Train the model\n",
            "model.fit(X, y, epochs=10, batch_size=10)\n",
            "\n",
            "# Evaluate the model\n",
            "loss, accuracy = model.evaluate(X, y)\n",
            "print(f\"Loss: {loss}\")\n",
            "print(f\"Accuracy: {accuracy}\")\n",
            "```\n",
            "\n",
            "In this script, we first generate simulated data using `np.random.rand` and `np.random.randint`. The input data `X` is a 2-dimensional array of random values between 0 and 1, and the target labels `y` are randomly assigned binary values.\n",
            "\n",
            "Next, we define the neural network model using the `Sequential` class from Keras. The model consists of two dense layers, with the first layer having 4 units and ReLU activation, and the second layer having 1 unit and sigmoid activation.\n",
            "\n",
            "After defining the model, we compile it using the `compile` method, specifying the loss function, optimizer, and metrics to track during training.\n",
            "\n",
            "Then, we train the model using the `fit` method, passing in the input data `X` and target labels `y`, as well as the number of epochs and batch size.\n",
            "\n",
            "Finally, we evaluate the trained model using the `evaluate` method, and print the loss and accuracy metrics.\n"
          ]
        }
      ],
      "source": [
        "print(response.content, end='\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VVEgKroxeIoi"
      },
      "source": [
        "# 2. Prompts\n",
        "\n",
        "A \"prompt\" refers to the input to the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eWHxofqXeMV3",
        "outputId": "eae45e16-b896-4175-ed76-63df345bf209"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain/__init__.py:24: UserWarning: Importing PromptTemplate from langchain root module is no longer supported.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from langchain import PromptTemplate\n",
        "\n",
        "template=\"\"\"\n",
        "You are an expert data scientist with an expertise in building deep leraning models.\n",
        "Explain the concept of {concept} in a couple of lines\n",
        "\"\"\"\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"concept\"],\n",
        "    template=template\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6iJFgOxefH2B",
        "outputId": "7f832810-108e-4296-806e-456112195cbb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "PromptTemplate(input_variables=['concept'], output_parser=None, partial_variables={}, template='\\nYou are an expert data scientist with an expertise in building deep leraning models.\\nExplain the concept of {concept} in a couple of lines\\n', template_format='f-string', validate_template=True)"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "FplAGUS9fX1b",
        "outputId": "641e3cfc-6fb5-4e04-83db-412550746003"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nRegularization is a technique used to prevent overfitting in deep learning models by penalizing large weights and encouraging generalization to unseen data. This is done by adding a “regularization term” to the loss function, which penalizes overly large weights and encourages the model to use simpler models with fewer parameters.'"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "llm(prompt.format(concept=\"regularization\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "ygQUUbhWfwaX",
        "outputId": "3a28b211-7524-47cd-ddfd-3a66fd25e5dc"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nAn autoencoder is a type of artificial neural network used for unsupervised learning, which attempts to reconstruct its input in an efficient and compressed form. It uses an encoder to learn an efficient representation of input data in a lower-dimensional latent space, and a decoder to reconstruct the input data from the encoded representation. They are used for dimensionality reduction, image denoising, and can also be used as generative models.'"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "llm(prompt.format(concept=\"autoencoder\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QLiY7mSzf3wk"
      },
      "source": [
        "# 3. Chains\n",
        "\n",
        "A chain is just an end-to-end wrapper around multiple individual components."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G9XGEa8if2x2",
        "outputId": "59c3e044-ba72-4b0f-ac6d-11929029a981"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Autoencoders are a type of artificial neural network that can be used to learn important features from unlabeled data in an unsupervised manner. They are composed of an encoder, which compresses inputs into a low-dimensional representation, and a decoder, which reconstructs the representation back into the input space. This process helps capture important features of the data and can be used for dimensionality reduction, feature extraction, feature learning, and more.\n"
          ]
        }
      ],
      "source": [
        "from langchain.chains import LLMChain\n",
        "chain = LLMChain(llm=llm, prompt=prompt)\n",
        "\n",
        "print(chain.run(\"autoencoder\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Kb2QrsGj6ym"
      },
      "source": [
        "3.1. Nested prompts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "6b7dvd4skGZn"
      },
      "outputs": [],
      "source": [
        "second_prompt = PromptTemplate(\n",
        "    input_variables=[\"ml_concept\"],\n",
        "    template=\"Turn the concept description of {ml_concept} and explain it to me like I'm five in 500 words\"\n",
        ")\n",
        "chain_two = LLMChain(llm=llm, prompt=second_prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NuxUQKAd8OJM",
        "outputId": "7b8261ef-ed1f-485a-b827-074f7c9b5f78"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
            "\u001b[36;1m\u001b[1;3m\n",
            "An autoencoder is a type of artificial neural network used for unsupervised learning, which can be used to represent complicated input data such as images, videos, or speech signals as simpler representations called \"encodings\". This process is known as feature extraction or dimensionality reduction. Autoencoders can also be used for anomaly detection and generative modeling.\u001b[0m\n",
            "\u001b[33;1m\u001b[1;3m\n",
            "\n",
            "An autoencoder is like a translator. It takes information in a complicated form, such as a picture, a video or a sound, and it changes it into a simpler form. This is known as “encoding” the information. It’s like a magical machine that can take a complex sentence and turn it into a few simple words!\n",
            "\n",
            "To use an autoencoder, we give it information in a complicated form like a picture or sound. Then it “encodes” it, or translates it into something simpler. For example, it might take a complex picture which is made up of lots of little coloured squares and turn it into a few numbers which describe the image.\n",
            "\n",
            "Autoencoders can also be used for “anomaly detection”. This is like putting your information through a metal detector. If something strange is detected, we can look at it more closely. Autoencoders can also be used for “generative modeling”. This is where it creates something new based on the information it already knows.\n",
            "\n",
            "In summary, an autoencoder is like a magical translator which can turn complicated information into simpler data. It can also be used to detect strange\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "from langchain.chains import SimpleSequentialChain\n",
        "overall_chain = SimpleSequentialChain(chains=[chain, chain_two], verbose=True)\n",
        "\n",
        "explanation = overall_chain.run(\"autoencoder\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bo7ZUL9A9l2M"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "2y0sV2Wo9mNY"
      },
      "outputs": [],
      "source": [
        "from langchain import text_splitter\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=100,\n",
        "    chunk_overlap = 0\n",
        ")\n",
        "\n",
        "texts = text_splitter.create_documents([explanation])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5BAEzTwd-HuK",
        "outputId": "5c3998d8-bf85-4d15-ab3c-bbef08000f09"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(page_content='An autoencoder is like a translator. It takes information in a complicated form, such as a picture,', metadata={}),\n",
              " Document(page_content='a video or a sound, and it changes it into a simpler form. This is known as “encoding” the', metadata={}),\n",
              " Document(page_content='information. It’s like a magical machine that can take a complex sentence and turn it into a few', metadata={}),\n",
              " Document(page_content='simple words!', metadata={}),\n",
              " Document(page_content='To use an autoencoder, we give it information in a complicated form like a picture or sound. Then', metadata={}),\n",
              " Document(page_content='it “encodes” it, or translates it into something simpler. For example, it might take a complex', metadata={}),\n",
              " Document(page_content='picture which is made up of lots of little coloured squares and turn it into a few numbers which', metadata={}),\n",
              " Document(page_content='describe the image.', metadata={}),\n",
              " Document(page_content='Autoencoders can also be used for “anomaly detection”. This is like putting your information', metadata={}),\n",
              " Document(page_content='through a metal detector. If something strange is detected, we can look at it more closely.', metadata={}),\n",
              " Document(page_content='Autoencoders can also be used for “generative modeling”. This is where it creates something new', metadata={}),\n",
              " Document(page_content='based on the information it already knows.', metadata={}),\n",
              " Document(page_content='In summary, an autoencoder is like a magical translator which can turn complicated information into', metadata={}),\n",
              " Document(page_content='simpler data. It can also be used to detect strange', metadata={})]"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "texts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "MNvWqysH-R6S",
        "outputId": "e62eea58-3cab-4726-b81b-a17d895acc01"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'An autoencoder is like a translator. It takes information in a complicated form, such as a picture,'"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "texts[0].page_content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eL23LQlK_JBm",
        "outputId": "a7c1d2e9-6079-459f-d7a4-b2b74ae1f226"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.6.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2023.7.22)\n",
            "Installing collected packages: tiktoken\n",
            "Successfully installed tiktoken-0.5.1\n"
          ]
        }
      ],
      "source": [
        "!pip install tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JZN5_hvX-XY7",
        "outputId": "1c9cd064-9c58-4c95-a150-7dae551e2366"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain/embeddings/openai.py:217: UserWarning: WARNING! model_name is not default parameter.\n",
            "                    model_name was transferred to model_kwargs.\n",
            "                    Please confirm that model_name is what you intended.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "\n",
        "embeddings = OpenAIEmbeddings(model_name=\"ada\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fsiJygGF-6io",
        "outputId": "83d1b44e-bb4a-4c95-8317-e77847465796"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[-0.0425466536451634,\n",
              " 0.0010285452607304234,\n",
              " 0.010034588545590245,\n",
              " 0.004037249611533585,\n",
              " 0.011432741140528255,\n",
              " 0.011084875414215233,\n",
              " -0.009593066232351784,\n",
              " -0.024069632012457716,\n",
              " 0.005104260704373378,\n",
              " -0.04096787942870548,\n",
              " 0.003053859872598454,\n",
              " 0.04364377020423489,\n",
              " 0.01692500617499145,\n",
              " -0.002015279960923831,\n",
              " 0.02807008879637999,\n",
              " -0.01739328631565108,\n",
              " 0.000556501529338229,\n",
              " 0.009118096402006233,\n",
              " -0.01141936176115641,\n",
              " -0.009907483510235193,\n",
              " -0.022290165242777073,\n",
              " 0.028846096525237102,\n",
              " -0.007191455062251508,\n",
              " -0.024310462703795978,\n",
              " -0.00854946905341272,\n",
              " 0.021259947443209852,\n",
              " 0.014195597881974659,\n",
              " -0.03106708653947873,\n",
              " 0.003017066346495249,\n",
              " -0.005335056395521493,\n",
              " 0.018329848459615383,\n",
              " -0.03566961539513404,\n",
              " -0.010522938686630165,\n",
              " -0.047818158919991145,\n",
              " -0.03101356902199135,\n",
              " -0.001459196362567999,\n",
              " 0.01673769300114057,\n",
              " -0.03079949708939678,\n",
              " -0.003187654364808798,\n",
              " 0.009258579885410607,\n",
              " 0.03409084117867612,\n",
              " 0.0009031129388351401,\n",
              " 0.003930213645236299,\n",
              " -0.01850378039144937,\n",
              " -0.003876696127748919,\n",
              " 0.00852271029466903,\n",
              " -0.004565737890689039,\n",
              " -0.025782201885279132,\n",
              " -0.008770230675693212,\n",
              " 0.02738773672312579,\n",
              " 0.0006819339094411702,\n",
              " 0.007305180252573454,\n",
              " -0.012436200181351784,\n",
              " -0.016429965412943087,\n",
              " -0.02202257765534017,\n",
              " 0.007392146684151709,\n",
              " -0.014784293368303418,\n",
              " -0.0034485536595435643,\n",
              " 0.021353604961457818,\n",
              " -0.01850378039144937,\n",
              " 0.0003062640148518885,\n",
              " -0.018169294044508195,\n",
              " -0.02728070168815103,\n",
              " 0.009231821126666918,\n",
              " 0.004826637185423806,\n",
              " -0.020082556470552338,\n",
              " 0.011586604934626998,\n",
              " 0.004328252509855002,\n",
              " 0.00476642951258924,\n",
              " -0.011071496034843389,\n",
              " 0.04326914385653313,\n",
              " 0.012957998770821317,\n",
              " -0.021982437654579585,\n",
              " -0.0007291800756786293,\n",
              " 0.031120604056966112,\n",
              " -0.03154874792215525,\n",
              " -0.008944163538849723,\n",
              " -0.008161465188984163,\n",
              " -0.017272871901304474,\n",
              " -0.0014842829317208395,\n",
              " 0.028284160728974557,\n",
              " -0.030264318189232878,\n",
              " -0.019654414468008245,\n",
              " 0.00889733477972574,\n",
              " 0.006753278059517269,\n",
              " -0.0018480366710379272,\n",
              " -0.013968147501330769,\n",
              " 0.014128700985115433,\n",
              " -0.0022510926865057564,\n",
              " 0.002435060084191151,\n",
              " 0.004779808891961086,\n",
              " 0.013225587289580744,\n",
              " 0.008020980774257265,\n",
              " -0.014449807021362242,\n",
              " 0.014570222367031371,\n",
              " -0.0009390702537276049,\n",
              " 0.040111595423617294,\n",
              " 0.02657159085615314,\n",
              " -0.01007472668370578,\n",
              " -0.018369986597730918,\n",
              " 0.004686152770696908,\n",
              " 0.019814967020470385,\n",
              " -0.013861111535033483,\n",
              " -0.01584127085793685,\n",
              " -0.02871230273151865,\n",
              " 0.003408415288597398,\n",
              " 0.006127788814254675,\n",
              " 0.008529399984354952,\n",
              " 0.0035355200911218196,\n",
              " -0.021474019375804423,\n",
              " -0.005632748983528833,\n",
              " 0.06400729364159598,\n",
              " 0.005793302467313499,\n",
              " -0.02556813181532961,\n",
              " 0.011546466796511463,\n",
              " 0.0030990155108090623,\n",
              " 0.0015001709447249056,\n",
              " 0.006037477537833459,\n",
              " 0.011258808277371744,\n",
              " -0.006388688108989442,\n",
              " -4.972870101115196e-05,\n",
              " 0.007459044046672196,\n",
              " 0.016563761069306585,\n",
              " -0.017821428318195172,\n",
              " 0.023761906286905277,\n",
              " -0.0006284161009155008,\n",
              " -0.002184195323985269,\n",
              " 0.012141851972526143,\n",
              " -0.011800675935899044,\n",
              " -0.008710022537197385,\n",
              " -0.004334942199540925,\n",
              " 0.0012309095378827363,\n",
              " 0.005141053997645952,\n",
              " 0.01966779384738009,\n",
              " -0.02350769621619517,\n",
              " 0.015265953819657415,\n",
              " 0.0017476908600878266,\n",
              " 0.024845641603959877,\n",
              " 0.003816488454914354,\n",
              " -0.03229799689226868,\n",
              " 0.029595345495350527,\n",
              " 0.008495951535925339,\n",
              " -0.037275152095625735,\n",
              " -0.016162377825506183,\n",
              " -0.014637119263890597,\n",
              " 0.008730091606255153,\n",
              " 0.014436427641990397,\n",
              " 0.026424415820417796,\n",
              " 0.007238283355714228,\n",
              " 0.02196905827520774,\n",
              " 0.012061575696295072,\n",
              " -0.012569994906392759,\n",
              " 0.017179216245701557,\n",
              " 0.009044508884138562,\n",
              " 0.02881933776649341,\n",
              " 0.03987076659492408,\n",
              " 0.009412443679509351,\n",
              " 0.01095777037886018,\n",
              " -0.016470105413703667,\n",
              " 0.021634571928266566,\n",
              " -0.006683035852153821,\n",
              " 0.005127674618274107,\n",
              " 0.002426697972083748,\n",
              " -0.00489018923744007,\n",
              " 0.030077006878027047,\n",
              " 0.02852498955766777,\n",
              " 0.01675107238051242,\n",
              " 0.004117526353425917,\n",
              " -0.007365387925408019,\n",
              " -0.011954539729997786,\n",
              " -0.023842182563136347,\n",
              " 0.015988444031027147,\n",
              " -0.012757307148921116,\n",
              " 0.029461551701632074,\n",
              " -0.004997225203737355,\n",
              " 0.011934470660940019,\n",
              " -0.00466608370163914,\n",
              " 0.0024668363430299144,\n",
              " -0.0302108006717455,\n",
              " -0.005000570048580316,\n",
              " 0.01220874886938537,\n",
              " 0.027936295002661538,\n",
              " 0.01985510515858592,\n",
              " 0.005040708186695852,\n",
              " -0.016884868036875916,\n",
              " -0.005903682812792483,\n",
              " 0.011513017416759325,\n",
              " -0.00810794767149678,\n",
              " 0.005716370570264128,\n",
              " -0.007706563962035118,\n",
              " 0.03593720670786103,\n",
              " 0.02107263613200402,\n",
              " 0.015694095822201506,\n",
              " -0.026692005270499745,\n",
              " -0.6349352249348504,\n",
              " -0.003916834265864455,\n",
              " 0.020925461096268676,\n",
              " -0.023962596977482955,\n",
              " 0.00899099136665118,\n",
              " 0.024845641603959877,\n",
              " -0.01566733706345782,\n",
              " -0.007372077615093941,\n",
              " -0.03170930047461739,\n",
              " 0.005595955690256259,\n",
              " -0.0032411721151268096,\n",
              " -0.0067800368182609596,\n",
              " -0.01630955099859648,\n",
              " -0.003956972869641252,\n",
              " -0.0004916948112599075,\n",
              " -0.01828971032149985,\n",
              " 0.0004116271803779176,\n",
              " -0.027267322308779183,\n",
              " 0.014784293368303418,\n",
              " -0.006495723609625465,\n",
              " 0.010596525273175313,\n",
              " 0.03620479429529794,\n",
              " -0.017955223974558673,\n",
              " 0.004916948461845022,\n",
              " -0.014476566711428456,\n",
              " 0.021300085581325387,\n",
              " 0.02053745723184012,\n",
              " -0.021701470687770837,\n",
              " 0.00033908547949641933,\n",
              " 0.005559161931322423,\n",
              " -0.046988633673646654,\n",
              " 2.963339485166894e-05,\n",
              " -0.002856512862710583,\n",
              " -0.008335398052140673,\n",
              " 0.011967919109369632,\n",
              " 0.015613819545970437,\n",
              " -0.004408529251747335,\n",
              " 0.03893420258831473,\n",
              " 0.02350769621619517,\n",
              " 0.047577330091297935,\n",
              " -0.020550836611211966,\n",
              " -0.026411036441045952,\n",
              " 0.022276785863405226,\n",
              " -0.006917176388144896,\n",
              " 0.004729636219316666,\n",
              " 0.005840130295114957,\n",
              " -0.01007472668370578,\n",
              " -0.01596168527228346,\n",
              " 0.0007814435673881881,\n",
              " -0.04733649753731463,\n",
              " -0.023039414212890498,\n",
              " 0.0074122162188707385,\n",
              " 0.007713253651721041,\n",
              " -0.00019828764563655258,\n",
              " 0.0035422097808077424,\n",
              " 0.011038047586413776,\n",
              " 0.03524147525523499,\n",
              " -0.018838266738390546,\n",
              " 0.006361928884584489,\n",
              " -0.015172298164054498,\n",
              " 0.013600211774637456,\n",
              " 0.015854650237308695,\n",
              " -0.013914629052520864,\n",
              " -0.009766999095508296,\n",
              " -0.01649686417244736,\n",
              " 0.011934470660940019,\n",
              " -0.010522938686630165,\n",
              " -0.018891786118522973,\n",
              " -0.0021808504791423077,\n",
              " -0.0006990763556766622,\n",
              " 0.011238739208313977,\n",
              " 0.010857425033571342,\n",
              " 0.019426963156041827,\n",
              " -0.010623284031919004,\n",
              " -0.00891740384878351,\n",
              " 0.02101911861451664,\n",
              " 0.02115291240823509,\n",
              " -0.012616822734194217,\n",
              " 0.004368390647970538,\n",
              " 0.026344139544186726,\n",
              " 0.02254437531348718,\n",
              " -0.012737238079863347,\n",
              " -0.03740894588934419,\n",
              " -0.007265042114457918,\n",
              " 0.023307003662972448,\n",
              " -0.002518681670926445,\n",
              " -0.018089017768277125,\n",
              " -0.025808960644022823,\n",
              " -0.01284427311483811,\n",
              " 0.014556842987659526,\n",
              " 0.015011744680269832,\n",
              " 0.01948048067352921,\n",
              " -0.016055340927886373,\n",
              " -0.03505416394402916,\n",
              " -0.01831646908024354,\n",
              " 0.008235052706851834,\n",
              " -0.022825344142940972,\n",
              " -0.003189326787230279,\n",
              " 0.023092933593022925,\n",
              " -0.017968603353930516,\n",
              " -0.0004026378516548014,\n",
              " -0.012810824666408496,\n",
              " 0.012717168079483056,\n",
              " 0.004843361409638612,\n",
              " 0.0016147325790882225,\n",
              " 0.016951764933735142,\n",
              " -0.026156826370335846,\n",
              " 0.0030036867342927726,\n",
              " 0.020176212126155252,\n",
              " -0.023587972492426244,\n",
              " -0.010716940618844444,\n",
              " 0.0009532859025178481,\n",
              " 0.007325249787292483,\n",
              " 0.01044266147907657,\n",
              " -0.003385001141866038,\n",
              " -0.03261910199719296,\n",
              " 0.001036071278042402,\n",
              " 0.022852102901684664,\n",
              " 0.014289253537577576,\n",
              " -0.04621262594478954,\n",
              " 0.025206886709644744,\n",
              " -0.0017777945800897938,\n",
              " 0.016175757204878027,\n",
              " 0.026919456582466163,\n",
              " 0.006057546606891226,\n",
              " 0.03663293816048708,\n",
              " -0.0021657986773489816,\n",
              " -0.02524702484776028,\n",
              " -0.014382910124503016,\n",
              " 0.010155003891259376,\n",
              " -0.007499182650448994,\n",
              " -0.0040038006974427096,\n",
              " -0.0032562239169201357,\n",
              " -0.021139533028863247,\n",
              " 0.020136073988039717,\n",
              " 0.006539206592583962,\n",
              " 0.0503870146605458,\n",
              " -0.005422022827099748,\n",
              " -0.005863544674676948,\n",
              " -0.021193050546350626,\n",
              " -0.027641946793835897,\n",
              " -0.01436953074513117,\n",
              " 0.005508989258678003,\n",
              " 0.017808048938823328,\n",
              " -0.005629404138685872,\n",
              " -0.0037462462475509046,\n",
              " -0.016577140448678432,\n",
              " -0.013473107670604926,\n",
              " -0.004743015598688512,\n",
              " 0.01250309707821101,\n",
              " -0.015132159094616439,\n",
              " -0.022597892830974558,\n",
              " -0.035321751531466064,\n",
              " 0.008495951535925339,\n",
              " 0.014048423777561839,\n",
              " -0.009787068164566063,\n",
              " 0.013553383946835997,\n",
              " -0.01402166501881815,\n",
              " -0.0352147164964913,\n",
              " -0.02675890216735897,\n",
              " 0.027989812520148916,\n",
              " 0.017915085836443134,\n",
              " -0.013914629052520864,\n",
              " 0.018115776527020813,\n",
              " -0.02162119254889472,\n",
              " -0.006729864145616541,\n",
              " 0.019828346399842232,\n",
              " 0.01701866183059437,\n",
              " -0.02183526448148929,\n",
              " -0.00587023436436287,\n",
              " 0.013647040533761437,\n",
              " -0.01820943404526878,\n",
              " -0.005619369604156988,\n",
              " 0.0266786258911279,\n",
              " 0.008054429222686878,\n",
              " 0.025434336158966113,\n",
              " 0.0006050020705994564,\n",
              " -0.017272871901304474,\n",
              " 0.027829258105041728,\n",
              " -0.033903529867470285,\n",
              " -0.008148085809612318,\n",
              " 0.0036024172208116764,\n",
              " -0.006368619039931673,\n",
              " -0.00984727630306189,\n",
              " -0.00013327187475554612,\n",
              " 0.036311829330272695,\n",
              " 0.013767454948108044,\n",
              " 0.01989524329670146,\n",
              " -0.01956075694976028,\n",
              " 0.002488577834509163,\n",
              " 0.005000570048580316,\n",
              " 0.01966779384738009,\n",
              " -0.0008721730076224327,\n",
              " 0.027802499346298037,\n",
              " 0.00010269774229179431,\n",
              " 0.020925461096268676,\n",
              " 0.0050106045831092,\n",
              " 0.009492720887062945,\n",
              " -0.012048196316923226,\n",
              " 0.009961001027722573,\n",
              " 0.009425823058881197,\n",
              " 0.006693070386682705,\n",
              " -0.013954768121958923,\n",
              " 0.007311869942259376,\n",
              " 0.022785206004825437,\n",
              " -0.011084875414215233,\n",
              " 0.0020938840475640524,\n",
              " -0.021393743099573353,\n",
              " 0.015466645441557616,\n",
              " -0.0004808240364164545,\n",
              " -0.01024196985717637,\n",
              " -0.02871230273151865,\n",
              " -0.00807449922306717,\n",
              " -0.0012493063009343388,\n",
              " -0.002020297228188273,\n",
              " 0.018677714185928406,\n",
              " 0.009512789956120713,\n",
              " 0.03724839333688205,\n",
              " -0.004482116303953745,\n",
              " -0.013506556119034539,\n",
              " -0.021380363720201506,\n",
              " -0.013031585357366465,\n",
              " 0.030077006878027047,\n",
              " 0.002026986917874195,\n",
              " -0.0033716217624941928,\n",
              " 0.02318658924862584,\n",
              " 0.01768763452447672,\n",
              " 0.014423048262618551,\n",
              " -0.007599528461399095,\n",
              " -0.049396933136449064,\n",
              " 0.008676574088767772,\n",
              " 0.02233030338089261,\n",
              " -0.0054119878269096025,\n",
              " 0.02617020761235274,\n",
              " -0.0049102587721590995,\n",
              " 0.006716484766244695,\n",
              " -0.005087536480158572,\n",
              " 0.012730547458854902,\n",
              " 0.010777147826017746,\n",
              " -0.0059973389340566615,\n",
              " -0.01790170645707129,\n",
              " 0.023614731251169932,\n",
              " -0.008602987502222624,\n",
              " -0.008710022537197385,\n",
              " 0.005445436741000477,\n",
              " 0.018597437909697333,\n",
              " 0.018142535285764504,\n",
              " -0.001751035704930788,\n",
              " -0.025073091053281246,\n",
              " -0.005592610845413298,\n",
              " -0.02332038304234429,\n",
              " 0.02694621534120985,\n",
              " -0.0046694285464821015,\n",
              " -0.01319213884115113,\n",
              " 0.022196509587174156,\n",
              " 0.02283872352231282,\n",
              " 0.01519905692279819,\n",
              " 0.009706791888334992,\n",
              " 0.04179740467504997,\n",
              " 0.026317380785443035,\n",
              " -0.0014332736986197333,\n",
              " 0.009445893059261487,\n",
              " 0.01222881886976566,\n",
              " 0.01820943404526878,\n",
              " 0.014476566711428456,\n",
              " 0.0009959329070962355,\n",
              " 0.0001773822635046435,\n",
              " -0.03363594228003338,\n",
              " -0.02551461429784223,\n",
              " 0.024885779742075412,\n",
              " -0.0021239878839813347,\n",
              " -0.007278421493829763,\n",
              " 0.005689611811520437,\n",
              " -0.02093884047564052,\n",
              " 0.01723273376318894,\n",
              " 0.005325021395331347,\n",
              " -0.014302633848271944,\n",
              " 0.022183130207802312,\n",
              " 0.03200364682079799,\n",
              " 0.025434336158966113,\n",
              " -0.03430491124862564,\n",
              " -0.03425139373113826,\n",
              " 0.028979892181600603,\n",
              " 0.011927780971254097,\n",
              " 0.002242730574398353,\n",
              " -0.026103308852848464,\n",
              " -0.027401116102497635,\n",
              " 0.0038967651968066864,\n",
              " -0.025527993677214075,\n",
              " -0.013205518220522976,\n",
              " -0.018383365977102765,\n",
              " 0.014730775850816037,\n",
              " 0.006248203694262543,\n",
              " 0.0025354061279718827,\n",
              " -0.030960049641858924,\n",
              " 0.0014031699786177664,\n",
              " 0.05710349663282292,\n",
              " -0.021995817033951433,\n",
              " -0.00781359946267114,\n",
              " 0.013954768121958923,\n",
              " -0.014035044398189995,\n",
              " -0.0029518414063962415,\n",
              " -0.013366071704307642,\n",
              " -0.000576152609205942,\n",
              " 0.04730973877857094,\n",
              " 0.029729141151714024,\n",
              " -0.00159633581603662,\n",
              " 0.0014575239401465182,\n",
              " 0.016001823410398994,\n",
              " -0.026906077203094316,\n",
              " -0.01539974854469839,\n",
              " 0.006425481402262016,\n",
              " -0.002048728409353444,\n",
              " 0.0026692006201822272,\n",
              " -0.0012819186545685267,\n",
              " 0.004010490387128632,\n",
              " -0.020524077852468275,\n",
              " -0.00818153425804193,\n",
              " 0.013031585357366465,\n",
              " 0.003987076473227903,\n",
              " 0.008689953468139618,\n",
              " -0.009432512748567119,\n",
              " -0.002364818109658333,\n",
              " 0.02204933641408386,\n",
              " 0.04404515531068034,\n",
              " 0.006733208990459502,\n",
              " -0.011345774243288738,\n",
              " -0.007077729871929562,\n",
              " -0.030157283154258117,\n",
              " 0.01768763452447672,\n",
              " -0.036071000501579485,\n",
              " -0.03492036642502061,\n",
              " 0.0004971302423373774,\n",
              " 0.006729864145616541,\n",
              " -0.00614116819362652,\n",
              " -0.011218670139256209,\n",
              " 0.031896611785823224,\n",
              " -0.01614899844613434,\n",
              " 0.025073091053281246,\n",
              " -0.0062314794700477375,\n",
              " -0.00633851497068376,\n",
              " -0.023146451110510304,\n",
              " -0.014289253537577576,\n",
              " -0.04185092219253735,\n",
              " -0.007873806669844444,\n",
              " 0.003057204717441415,\n",
              " -0.007465733736358119,\n",
              " -0.010121554511507239,\n",
              " 0.02381542380439266,\n",
              " -0.005692956656363398,\n",
              " 0.00525477965362916,\n",
              " 0.023494316836823327,\n",
              " -0.002828081448714781,\n",
              " -0.03687376698918029,\n",
              " 0.022169750828430465,\n",
              " 0.016884868036875916,\n",
              " -0.006786726507946882,\n",
              " 0.0015277661475099672,\n",
              " -0.02852498955766777,\n",
              " 0.02333376242171614,\n",
              " 0.0006091831266531579,\n",
              " 0.020871943578781298,\n",
              " 0.006559276127302991,\n",
              " 0.018784749220903167,\n",
              " 0.012697099010425289,\n",
              " 0.01675107238051242,\n",
              " 0.020082556470552338,\n",
              " -0.02286548228105651,\n",
              " 0.005910372502478406,\n",
              " -0.03058542515680221,\n",
              " 0.0008571210894137914,\n",
              " 0.01820943404526878,\n",
              " 0.01739328631565108,\n",
              " -0.027534909896216087,\n",
              " 0.011158462000760382,\n",
              " -0.032779654549655105,\n",
              " -0.0343851912501468,\n",
              " 0.0004411037710756583,\n",
              " -0.0022745068332371164,\n",
              " -0.016269412860480944,\n",
              " 0.012690409320739365,\n",
              " 0.004023869766500477,\n",
              " -0.002501957446711639,\n",
              " -0.0008182370934913932,\n",
              " -0.015948305892911612,\n",
              " -0.022571134072230867,\n",
              " -0.006790071352789844,\n",
              " -0.018998821153497734,\n",
              " -0.0034619330389154095,\n",
              " 0.01014162451188753,\n",
              " -0.007780151014241528,\n",
              " -0.008054429222686878,\n",
              " -0.01689824741624776,\n",
              " 0.012095024144724685,\n",
              " -0.013847732155661638,\n",
              " -0.03267261951468034,\n",
              " -0.040405941769797886,\n",
              " -0.0055524722416365,\n",
              " -0.016389827274827552,\n",
              " 0.009666653750219457,\n",
              " 0.01424911539946204,\n",
              " -0.04169036964007521,\n",
              " 0.013887870293777173,\n",
              " 0.005161123532364982,\n",
              " -0.0010904252395711538,\n",
              " -0.013071723495482,\n",
              " 0.0033314833915480263,\n",
              " -0.0306121839155459,\n",
              " -0.026919456582466163,\n",
              " -0.0005289064429684829,\n",
              " -0.019346686879810757,\n",
              " -0.03882716755333997,\n",
              " -0.005211296205009402,\n",
              " -0.008455813397809804,\n",
              " 0.0162560334811091,\n",
              " 0.008141396119926394,\n",
              " -0.0012141851972526142,\n",
              " 0.011760537797783509,\n",
              " 0.001152305218411884,\n",
              " 0.01050955930725832,\n",
              " 0.011526397727453693,\n",
              " 0.011533087417139617,\n",
              " 0.005308297171116541,\n",
              " -0.03280641330839879,\n",
              " 0.006101029589849723,\n",
              " -0.007352008546036173,\n",
              " 0.001650689777565372,\n",
              " -0.028257401970230866,\n",
              " 0.03679349071294922,\n",
              " 0.0062716176081632725,\n",
              " 0.020029038953064956,\n",
              " 0.00520795136016644,\n",
              " 0.01029548737466375,\n",
              " -0.018998821153497734,\n",
              " 0.00021699797334026833,\n",
              " 0.03524147525523499,\n",
              " -0.0023213348938692056,\n",
              " -0.018998821153497734,\n",
              " -0.008910714159097586,\n",
              " -0.0046694285464821015,\n",
              " -0.019038959291613273,\n",
              " -0.014155459743859124,\n",
              " 0.0005719715531522404,\n",
              " 4.25947377397375e-05,\n",
              " 0.006529172058055078,\n",
              " -0.02635751892355857,\n",
              " 0.027909536243917846,\n",
              " -0.008121327050868626,\n",
              " -0.00559930053509922,\n",
              " 0.00243171523934819,\n",
              " 0.0009825534113090748,\n",
              " -0.002617355059455065,\n",
              " 0.003187654364808798,\n",
              " 0.019520618811644744,\n",
              " 0.013018205977994619,\n",
              " 0.025501234918470384,\n",
              " 0.0016841384588256157,\n",
              " -0.00861636688159447,\n",
              " -0.03486684890753323,\n",
              " 0.003492036875332692,\n",
              " -0.006943935146888586,\n",
              " 0.003318104012176181,\n",
              " 0.008475882466867571,\n",
              " -0.020617733508071192,\n",
              " 0.0033130865120811082,\n",
              " 0.012516476457582856,\n",
              " 0.005940476571726319,\n",
              " -0.016911626795619607,\n",
              " -0.004067353215120236,\n",
              " -0.041824163433793665,\n",
              " -0.012389372353550325,\n",
              " 0.017072179348081747,\n",
              " -0.0002425025607869925,\n",
              " 0.057745710567961586,\n",
              " -0.0003930213936274588,\n",
              " -1.4607642804160087e-05,\n",
              " -0.011787296556527199,\n",
              " -0.029167203492806434,\n",
              " 0.004682807925853946,\n",
              " -0.03545554532518451,\n",
              " -0.01621589534299356,\n",
              " 4.330029458677825e-05,\n",
              " 0.019641035088636398,\n",
              " 0.011533087417139617,\n",
              " 0.05413325951111292,\n",
              " -0.0010210193598337606,\n",
              " 0.0016122238290406862,\n",
              " 0.01316538008240744,\n",
              " 0.001449161828039115,\n",
              " 0.007271731804143841,\n",
              " 0.019426963156041827,\n",
              " 0.0065057581441543486,\n",
              " -0.040486218046028956,\n",
              " 0.009037819194452639,\n",
              " 0.02556813181532961,\n",
              " -0.0018413469813520046,\n",
              " -0.0017326389418791854,\n",
              " 0.00015679044602484758,\n",
              " 0.02026986778175817,\n",
              " 0.018169294044508195,\n",
              " 0.012904480322011412,\n",
              " -0.008850506951924283,\n",
              " 0.01289779063232549,\n",
              " -0.005592610845413298,\n",
              " 0.00525477965362916,\n",
              " 0.03334159220856269,\n",
              " 0.015801132719821316,\n",
              " 0.00930540864453459,\n",
              " 0.0047864985816470085,\n",
              " -0.005856854984991025,\n",
              " 0.03968345155842815,\n",
              " -0.008562848432784565,\n",
              " 0.03307400462112579,\n",
              " 0.009051198573824484,\n",
              " 0.042707209922915636,\n",
              " 0.0017242768297717822,\n",
              " 0.025461094917709804,\n",
              " -0.0069372454572026645,\n",
              " -0.005194571980794595,\n",
              " 0.019734690744239315,\n",
              " -0.00473967075384555,\n",
              " -0.031120604056966112,\n",
              " -0.004759739822903318,\n",
              " 0.0212733268225817,\n",
              " 0.029622104254094218,\n",
              " 0.004846706254481573,\n",
              " 0.009593066232351784,\n",
              " -0.016577140448678432,\n",
              " 0.0056494732077436395,\n",
              " 0.0038700062052323654,\n",
              " 0.006669656472781975,\n",
              " -0.022584513451602714,\n",
              " -0.02088532295815314,\n",
              " -0.004518909597226319,\n",
              " -0.006803451197822951,\n",
              " -0.031120604056966112,\n",
              " -0.024939297259562794,\n",
              " -0.029515069219119457,\n",
              " 0.013700558051248818,\n",
              " 0.02159443379015103,\n",
              " -0.023226727386741378,\n",
              " 0.03692728450666767,\n",
              " -0.03077273833065309,\n",
              " -0.03754273968306264,\n",
              " 0.012416131112294016,\n",
              " 0.01998890081494942,\n",
              " 0.04230582481647018,\n",
              " -0.004535633821441126,\n",
              " 0.03411759993741981,\n",
              " 0.018838266738390546,\n",
              " -0.00872340191656923,\n",
              " -0.018891786118522973,\n",
              " 0.009773688785194218,\n",
              " 0.0058501652953051025,\n",
              " -0.013118552254605982,\n",
              " 0.009920862889607038,\n",
              " 0.0171925956250734,\n",
              " 0.007338629166664328,\n",
              " -0.01898544177412589,\n",
              " 0.011994677868113323,\n",
              " 0.007913945739282504,\n",
              " 0.004502185373011513,\n",
              " -0.051484127494327195,\n",
              " -0.00496377628964648,\n",
              " 0.02283872352231282,\n",
              " 0.008977611987279336,\n",
              " -0.02056421599058381,\n",
              " -0.006535861747741,\n",
              " -0.008435744328752036,\n",
              " 0.004324907665012041,\n",
              " -0.01244957956072363,\n",
              " -0.009044508884138562,\n",
              " -0.01901220053286958,\n",
              " -0.019025579912241426,\n",
              " -0.02586248002415525,\n",
              " 0.019025579912241426,\n",
              " -0.019761449502983006,\n",
              " -0.008710022537197385,\n",
              " -0.005619369604156988,\n",
              " -0.02202257765534017,\n",
              " 0.011138392931702613,\n",
              " -0.016470105413703667,\n",
              " -0.009071267642882252,\n",
              " 0.012061575696295072,\n",
              " -0.009004370746023026,\n",
              " 0.009285339575476823,\n",
              " 0.0057264051047930115,\n",
              " 0.028899614042724484,\n",
              " -0.009867345372119658,\n",
              " 0.02392245883936742,\n",
              " 0.007820289152357064,\n",
              " 0.0062013758664610855,\n",
              " -0.012569994906392759,\n",
              " 0.028872855283980793,\n",
              " -0.04051297680477265,\n",
              " -0.02048393971435274,\n",
              " 0.0028866166991278657,\n",
              " 0.0042011474744999494,\n",
              " -0.005689611811520437,\n",
              " 0.0009482686352534061,\n",
              " 0.002741115017136526,\n",
              " -0.0306121839155459,\n",
              " -0.016697554863025037,\n",
              " 0.010409213030646958,\n",
              " 0.011707020280296127,\n",
              " -0.004097456818706888,\n",
              " -0.01633630975734017,\n",
              " -0.014008285639446304,\n",
              " -0.005117640083745223,\n",
              " 0.0008780264860976149,\n",
              " 0.009619825922417998,\n",
              " 0.022972517316031272,\n",
              " 0.026558211476781297,\n",
              " -0.02427032456568044,\n",
              " 0.005575886155537229,\n",
              " -0.020470560334980892,\n",
              " 0.00415097480185553,\n",
              " 0.024966056018306485,\n",
              " 0.027053250376184612,\n",
              " -0.012008057247485169,\n",
              " 0.0034050704437544365,\n",
              " 0.052072823911978476,\n",
              " -0.008228362085843387,\n",
              " 0.030933290883115232,\n",
              " 0.014811052127047109,\n",
              " 0.0058802688988917546,\n",
              " -0.010362385202845499,\n",
              " 0.014570222367031371,\n",
              " 0.002619027481876546,\n",
              " -0.029140444734062743,\n",
              " 0.018436883494590144,\n",
              " -0.029541827977863144,\n",
              " -0.002918392725135998,\n",
              " 0.013071723495482,\n",
              " -0.008656505019710005,\n",
              " 0.005739784484164856,\n",
              " 0.013459728291233082,\n",
              " -0.014757534609559728,\n",
              " -0.006428826247104977,\n",
              " -0.023761906286905277,\n",
              " -0.0030739289416562214,\n",
              " -0.012422820801979938,\n",
              " -0.010462730548134338,\n",
              " 0.007111178320359175,\n",
              " 0.008141396119926394,\n",
              " 0.0015026795783571266,\n",
              " 0.038077918583226546,\n",
              " -0.018436883494590144,\n",
              " -0.011606674003684765,\n",
              " -0.005120984928588185,\n",
              " 0.0038633165155464427,\n",
              " 0.020136073988039717,\n",
              " -0.02738773672312579,\n",
              " -0.010081416373391704,\n",
              " -0.005224675584381246,\n",
              " 0.004425253475962142,\n",
              " -0.020136073988039717,\n",
              " -0.008061119843695324,\n",
              " 0.00881705850349467,\n",
              " -0.014155459743859124,\n",
              " -0.02116629178760694,\n",
              " 0.027481392378728705,\n",
              " 0.03098680840060261,\n",
              " -0.02233030338089261,\n",
              " -0.006345204660369683,\n",
              " 0.008087878602439013,\n",
              " 0.004569082735532,\n",
              " 0.00790725604959658,\n",
              " -0.029220721010293816,\n",
              " -0.02554137305658592,\n",
              " 0.005820061226057189,\n",
              " 0.008810368813808747,\n",
              " -0.014088561915677375,\n",
              " 0.007452354356986274,\n",
              " -0.021781746964001907,\n",
              " 0.00943920243825304,\n",
              " -0.008020980774257265,\n",
              " -0.020657873508831772,\n",
              " -0.013105172875234137,\n",
              " 0.004375080803317722,\n",
              " -0.04083408563498703,\n",
              " -0.0015996806608795813,\n",
              " -0.02262465158971825,\n",
              " -0.006248203694262543,\n",
              " 0.0125298558369547,\n",
              " 0.0212733268225817,\n",
              " -0.006368619039931673,\n",
              " 0.01974807012361116,\n",
              " 0.0004808240364164545,\n",
              " 0.020202970884898943,\n",
              " -0.012757307148921116,\n",
              " 0.017205975004445248,\n",
              " -0.011031357896727852,\n",
              " -0.004569082735532,\n",
              " -0.02703987099681277,\n",
              " -0.0035990723759687154,\n",
              " -0.04326914385653313,\n",
              " -0.026210345750468274,\n",
              " -0.0001455015364721955,\n",
              " -0.036606179401743384,\n",
              " -0.009365615851707892,\n",
              " 0.041396023293894614,\n",
              " -0.012215439490393816,\n",
              " -0.00763966659951463,\n",
              " 0.009419133369195273,\n",
              " 0.006756622904360231,\n",
              " 0.004726291374473705,\n",
              " -0.023587972492426244,\n",
              " 0.028979892181600603,\n",
              " -0.022116233310943086,\n",
              " -0.019319928121067066,\n",
              " 0.002856512862710583,\n",
              " 0.004234596388590825,\n",
              " -0.021353604961457818,\n",
              " -0.005753163863536702,\n",
              " 0.01652362293119105,\n",
              " 0.013379451083679486,\n",
              " -0.008863886331296127,\n",
              " -0.02099235985577295,\n",
              " -0.004973810824175365,\n",
              " -0.003150860838705593,\n",
              " -0.010616594342233082,\n",
              " 0.022972517316031272,\n",
              " 0.04013835418236098,\n",
              " -0.017567220110130115,\n",
              " 0.04099463818744917,\n",
              " 0.0016005168720903216,\n",
              " 0.003017066346495249,\n",
              " -0.029568586736606835,\n",
              " -0.013613592085331824,\n",
              " -0.02823064134884213,\n",
              " 0.010937701309802412,\n",
              " 0.023454178698707792,\n",
              " 0.017272871901304474,\n",
              " 0.017366527556907388,\n",
              " -0.0053751945336370285,\n",
              " 0.019641035088636398,\n",
              " -0.0474167738135457,\n",
              " 0.0019283134129302602,\n",
              " -0.003890075507120764,\n",
              " 0.026906077203094316,\n",
              " -0.018704472944672094,\n",
              " 0.04674780111966335,\n",
              " -0.0014165493579896115,\n",
              " -0.0368470082304366,\n",
              " 0.021474019375804423,\n",
              " -0.008756851296321366,\n",
              " -0.017272871901304474,\n",
              " -0.003749591325224497,\n",
              " -0.005141053997645952,\n",
              " 0.006355239194898566,\n",
              " -0.027829258105041728,\n",
              " 0.009459272438633332,\n",
              " 0.007920635428968426,\n",
              " -0.005776578243098692,\n",
              " -0.009659964060533533,\n",
              " 0.021005739235144795,\n",
              " 0.004375080803317722,\n",
              " -0.011753848108097585,\n",
              " 0.0011581586968870663,\n",
              " 0.19298521114072115,\n",
              " -0.018369986597730918,\n",
              " -0.0021039188149235668,\n",
              " 0.006097684745006762,\n",
              " -0.00930540864453459,\n",
              " 0.004642669787738411,\n",
              " 0.01112501355233077,\n",
              " -0.015426507303442081,\n",
              " -0.02207609517282755,\n",
              " -0.006405412333204248,\n",
              " -0.015078641577129058,\n",
              " -0.002950168983974761,\n",
              " -0.021086015511375865,\n",
              " -0.001834657291666082,\n",
              " -0.0030873083210280665,\n",
              " 0.021032497993888486,\n",
              " -0.027160285411159377,\n",
              " -0.011573225555255152,\n",
              " -0.005900337967949522,\n",
              " -0.0038265229894432376,\n",
              " -0.024578052153877927,\n",
              " -0.0022561099537701983,\n",
              " -0.009118096402006233,\n",
              " -0.030451631363083757,\n",
              " 0.013299174807448416,\n",
              " 0.014583601746403217,\n",
              " 0.00010656524096933996,\n",
              " -0.0011456155287259615,\n",
              " 0.02267816910720563,\n",
              " 0.009218441747295072,\n",
              " -0.03513444022026023,\n",
              " 0.004488805993639668,\n",
              " 0.004846706254481573,\n",
              " 0.019467101294157366,\n",
              " -0.016791210518627954,\n",
              " 0.014637119263890597,\n",
              " 0.0119879881784274,\n",
              " -0.011064806345157465,\n",
              " 0.011011288827670085,\n",
              " 0.03708784078441991,\n",
              " 0.0050607772557536195,\n",
              " -0.020470560334980892,\n",
              " 0.012590063975450526,\n",
              " -0.026223725129840118,\n",
              " 0.014436427641990397,\n",
              " 0.020871943578781298,\n",
              " ...]"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "query_result = embeddings.embed_query(texts[0].page_content)\n",
        "query_result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GnbfuQv9APwI"
      },
      "source": [
        "# 4. Agents\n",
        "Some applications will require not just a predetermined chain of calls to LLMs/other tools,but potentially an unknown chain that depends on the user's input.   \n",
        "\n",
        "In these types of chains, there is a “agent” which *has access to a suite of tool*.  \n",
        "\n",
        "Depending on the user input, the agent can then decide which, if any, of these tools to call."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "lYnWLzfeAUds"
      },
      "outputs": [],
      "source": [
        "from langchain.agents.agent_toolkits import create_python_agent\n",
        "from langchain.tools.python.tool import PythonREPLTool\n",
        "from langchain.python import PythonREPL\n",
        "from langchain.llms.openai import OpenAI\n",
        "\n",
        "agent_executor = create_python_agent(\n",
        "    llm=OpenAI(temperature=0, max_tokens=1000),\n",
        "    tool=PythonREPLTool(),\n",
        "    verbose=True\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "id": "Dgy2ESJ9LgnN",
        "outputId": "901f88c8-754d-43f0-8cf6-aa820be73657"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:langchain.utilities.python:Python REPL can execute arbitrary code. Use with caution.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32;1m\u001b[1;3m I need to solve a quadratic equation\n",
            "Action: Python_REPL\n",
            "Action Input: import numpy as np\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I can use numpy to solve the equation\n",
            "Action: Python_REPL\n",
            "Action Input: np.roots([3,2,-1])\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
            "Final Answer: The roots of the equation are -1 and 0.33333\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'The roots of the equation are -1 and 0.33333'"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "agent_executor.run(\"Find the roots (zeros) if quadratic function 3 * x**2 + 2*x -1\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
